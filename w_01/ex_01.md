# Exercise notebook #1: *Introduction to Probability*

### Stochastic Modelling and Simulation; Spring 2021 @ University of Trieste

### Submitted by: [Emanuele Ballarin](mailto:emanuele@ballarin.cc)



## Exercise 1

Let $X$ be a random variable distributed uniformly along the interval $[a,b]$, i.e. $X \sim \mathcal{U}(a,b)$. Show that:

-   $\mathbb{E}[X] = \frac{a+b}{2}$;
-   $Var(X) = \frac{(b-a)^2}{12}$.

### Solution:

The *r.v.* $X$ is a continuous *r.v.* (being it a *uniform r.v.* along an interval). As such, its expected value $\mathbb{E}[X]$ and variance $Var(X)$ are defined as follows – being $p(x)$ the *p.d.f.* of $X$, defined over all possible outcomes $X=x \in (-\infty, +\infty)$.

-   $\mathbb{E}[X] = \int_{-\infty}^{+\infty}{x\ p(x)\ dx}$
-   $Var(X) = \int_{-\infty}^{+\infty}{(x -\mathbb{E}[X])^2 \ p(x)\ dx}$

The latter can be reworked by exploiting linearity of integral operators over fixed domains and invariance of $\mathbb{E}[X]$ *w.r.t.* sampling (i.e. specific realizations $x$ of $X$), thus leading to:

-   $Var(X) = \mathbb{E}[X^2] - \mathbb{E}[X]^2$, with $\mathbb{E}[f(X)]$ generally denoting $\int_{-\infty}^{+\infty}{f(x)\ p(x)\ dx}$.

In the specific case of a uniform distribution along an interval $X \sim \mathcal{U}(a,b)$, the *p.d.f.* $p(x)$ can be built by imposing both:

-   The uniformity constraint $p(x) = \propto \tilde{p}(x) \ \and\ \tilde{p}(x) = \tilde{p}(x')\ \forall x,x' \in (a,b)\ \and\ \tilde{p}(x'') = 0 \ \forall x'' \in (-\infty, +\infty) \setminus (a,b)$;
-   The normalization constraint $\int_{-\infty}^{+\infty}{p(x)\ dx} \ =\ 1$,

which univocally determine the (normalized) *p.d.f.* $p(x) = \frac{1}{b-a}$.

From previous definitions, for the expected value of  $X$:

-   $\mathbb{E}[X] = \int_{-\infty}^{+\infty}{x\ p(x)\ dx} \ = \ \frac{1}{b-a}\int_{a}^{b}{x\ dx} = \frac{b^2 - a^2}{2(b-a)} = \frac{(b - a)(b+a)}{2(b-a)} = \frac{a+b}{2}$.

For the variance of $X$, we first compute:

-   $\mathbb{E}[X^2] = \int_{-\infty}^{+\infty}{x^2\ p(x)\ dx} \ = \ \frac{1}{b-a}\int_{a}^{b}{x^2\ dx} = \frac{b^3 - a^3}{3(b-a)} = \frac{(b-a)(a^2+b^2+ab)}{3(b-a)}= \frac{a^2+b^2+ab}{3} = \frac{4a^2+4b^2+4ab}{12}$.
-   $\mathbb{E}[X]^2 = \frac{(a+b)^2}{4}= \frac{a^2+b^2+2ab}{4} = \frac{3a^2+3b^2+6ab}{12}$

Then, simply by differencing:

-   $Var(X) = \mathbb{E}[X^2] - \mathbb{E}[X]^2 = \frac{a^2+b^2-2ab}{12} = \frac{(b-a)^2}{12}$

---

## Exercise 2

Suppose that you have 8 cards. 5 of them are green ($G$) and 3 are yellow ($Y$). The five $G$ cards are numbered 1, 2, 3, 4, 5. The three $Y$ cards are numbered 1, 2, 3. The cards are well shuffled. You randomly draw 1 card. Denote with $E$ the event of drawing an even-numbered card, and compute.

1.  $P(G)$
2.  $P(G|E)$
3.  $P(G \and E)$
4.  $P(G \or E)$
5.  Are $G$ and $E$ mutually exclusive?

### Solution 1: *Counting frenzy*

The entire problem *could* be solved with no more than counting and the computation of ratios. Indeed, being the event set (the set of all possible outcomes we could witness in repeatedly *experiencing* the situation described until a fixed point is reached) discrete and finite, we can fall-back to the Laplacian *common-sense based* approach to probability.

Specifically, we are interested in the event of drawing 1 card from a finite deck composed of cards satisfying the properties described before. The set of all possible events we can witness (and therefore think of) has as elements each and all the events of *extracting one specific card* of the deck, among all of them. Its cardinality is easily computed as $|\Omega| = 8$.

Since the two properties $G$ (whose opposite $¬G = Y$) and $E$ (whose opposite $¬E = O$) are sufficient to univocally identify the cards of the deck (by replacing the number of each given-colour card with its *even*/*odd* specification, eventually indexed to preserve distinguishability), so are the events of the event set.
I.e.: $\Omega := \{\text{1G, 2G, 3G, 4G, 5G, 1Y, 2Y, 3Y}\} = {\{\text{OG, EG, OG', EG', OG'', OY, EY, OY'}\}}$. In such description, the juxtaposition of property specifiers ($G$, $Y$, $E$, $O$) denotes that both properties are satisfied; meaning that e.g. $OY \equiv (O \and Y)$ and the presence of a given index (or lack thereof) specifies that the event is distinguishable from all others identified by the same pair of properties (which they satisfy) but a different index.

By acknowledging that $p(\text{property}) = p(e\ \text{s.t.}\ \text{property}(e)\ \text{is true}) = \frac{\#\ e \in \Omega\ \text{s.t.}\ \text{property}(e)\ \text{is true}}{\#\ e \in \Omega} = \frac{|\Omega_{\text{property}}|}{|\Omega|}$, points (i), (iii) and (iv) are directly solvable by counting the specific events satisfying the proposed property (or their conjunction / disjunction) and dividing the result by $|\Omega|$.

Point (ii) can be solved by acknowledging that, in the Laplacian approach to probability, the conditioning set contains the truth condition that defined the (new) event set to consider. In our case, conditioning on $E$ is equivalent to redefining the event set as $\Omega_E$ and then computing $p(\text{property}| E) = \frac{|\Omega_{\text{property}|E}|}{|\Omega_E|}$.

Point (v) is solved by noticing that $|\Omega_{G \and E}| >0$ (meaning the events are not mutually exclusive).

### Solution 2: *Three numbers suffice*

At the totally opposite end of the spectrum there is the approach consisting in counting the *least possible* in order to solve all the possible problems involving the situation just described. What follows could be even performed without knowing which questions we we will be going to answer. The counting procedure is the same as before, but it is performed just *w.r.t.* the four properties $G\and E$, $G\and O$, $Y\and E$, $Y\and O$, thus leading to the corresponding probabilities.

The probability of one property could even be computed from the remaining three, via normalization, i.e. $p(\Omega)=1$. Such three numbers (to be obtained by counting) fully describe the outcome-generating process *w.r.t.* the properties we are interested in.

The process just described is indeed the construction of a probability mass function of the event *draw of a card from the deck* according to the two coordinates *even or odd* and *green or yellow*.

Probabilities involving just one among all (two) properties can be computed by marginalizing (i.e. summing over all possible values of) the other variable(s); unions of events can be reduced to set-theoretical operations involving negations of single properties and intersections – or just by exploiting the weak version of disjointness axiom (even pre-dating Kolmogorov’s) *a.t.w.* $p(¬A) = 1-p(A)$.

Conditioning is performed via quotient of probabilities, i.e. $p(A|B) = \frac{p(A\and B)}{p(B)}$.

Point (v) is addressed by noticing that $p(G\and E)>0$.

### The actual solution: putting numbers in

Either way they are computed (or in a mix of them):

1.  $P(G)= \frac{5}{3+5}=\frac{5}{8}$. E.g. via direct plug-in of numbers given by the text.
2.  $P(G|E) = \frac{P(G\and E)}{P(E)} = \frac{2/8}{3/8} = \frac{2}{3}$. E.g. via definition of conditional probability. Counting is used to determine:
3.  $P(G\and E) = \frac{2}{8} = \frac{1}{4}$.
4.  $P(G \or E) = 1-P(Y\and O) = 1-\frac{2}{8} = \frac{3}{4}$. E.g. $P(Y\and O)$ via counting.
5.  They are not.

*P.S.: Was the exercise **only** about this third part?* :speak_no_evil:

---

## Exercise 3

Consider a population containing $n$ individuals, $m$ of which are infected. You invite 2 people over for dinner. What is the probability that at least one of the two guests are infected?

### Solution:

The problem can be easily solved when mapped to an *urns and balls sampling problem*, where $n$ balls – $m$ red and $(n-m)$ black – are put inside an urn. The probability $p_?$ to be determined is that of extracting, twice and without replacement, at least one red ball. The order of extraction is irrelevant.

The most straightforward way to attack the problem is to consider the complementary event (i.e. extracting – in the same setting as before – exactly two black balls), and then compute $p_? = 1-p_{BB}$. This way, both the problem of draw order and that of asymmetry between first and second draw due to lack of replacement are solved. *For free!*

We can now compute $p_{BB} = \frac{n-m}{n}\frac{n-m-1}{n-1}$ and the requested $p_? = 1-\frac{n-m}{n}\frac{n-m-1}{n-1}$.

---

## Exercise 4

Let $X$ be a discrete random variable. Prove that:

1.  $\mathbb{E}[aX + b] = a\mathbb{E}[X]+b$;
2.  $Var(aX + b) = a^2Var(X)$;
3.  $\mathbb{E}[X + Y] = \mathbb{E}[X]+\mathbb{E}[Y]$;
4.  $Var(X + Y) = Var(X)+ Var(Y)$ if $X$ and $Y$ are independent. How can you express the covariance among $X$ and $Y$ in case they are not *i.r.v.*?

### Solution:

Being $X$ a discrete *r.v.*, we acknowledge the following definitions for $E[f(X)]$ and $Var(f(X))$, with $f$ any function preserving the well-posedness of the problem.

-   $E[f(X)] = \sum_{\ i \in \Omega \ } f(x_i)\ p(x_i)$
-   $Var(f(X)) = \sum_{\ i \in \Omega \ } (f(x_i) - E[f(X)])^2\ p(x_i)$

with $\Omega$ being the event set for $X$, $i \in \Omega$ the index of any possible realization of $X$, $p(x)$ the (normalized) probability mass function for $X$ and $f$ including the identity function.

1.  $\mathbb{E}[aX + b] = \sum_{i \in \Omega} p(x_i)\ (ax_i+b) = \sum_{i \in \Omega} p(x_i)\ (ax_i) + \sum_{i \in \Omega} p(x_i)\ (b) = a\sum_{i \in \Omega} p(x_i)\ (x_i) + b\sum_{i \in \Omega} p(x_i) =\\= a\mathbb{E}[X]+b$ 
2.  XYZ|YXYXYXYXYX
3.  $\mathbb{E}[X + Y] = \sum_{i \in \Omega} p(x_i)\ (ax_i+b) = \sum_{i \in \Omega} p(x_i)\ (ax_i) + \sum_{i \in \Omega} p(x_i)\ (b) = a\sum_{i \in \Omega} p(x_i)\ (x_i) + b\sum_{i \in \Omega} p(x_i) =\\= a\mathbb{E}[X]+b$ 



---

## Exercise 5

Let $V = \frac{1}{3}(U_1 + U_2 + U_3)$ be a random variable defined as the sum of three *i.i.d.* and uniformly distributed random variables $U_i \sim U(0,1)$. Determine the expected value and the variance of $V$.

---

## Exercise 6

${}^{14}C$ is a radioactive element with a half-life of about $5730$ years. ${}^{14}C$ decays following an exponential distribution with a rate of $0.000121$. We start with 1 gram of ${}^{14}C$. We are interested in the time (in years) if takes to decay.

1.  Find the percentage of ${}^{14}C$ lasting less than $5730$ years;
2.  Find the percentage of ${}^{14}C$ lasting more than $10000$ years;
3.  How many years are necessary for $30\%$ of ${}^{14}C$ to decay?

---

## Exercise 7

1.  The patient recovery time from a particular surgical procedure is normally distributed with a mean of $5.3$ days and a standard deviation of $2.1$ days.
    -   What is the median recovery time?
    -   What is the $z$-score for a patient who takes 10 days to recover?
2.  The lenght of time to find a parking space at 9 A.M. follows a normal distribution with a mean of 5 minutes and a standard deviation of 2 minutes.
    -   Find the probability that it takes at least 8 minutes to find a parking space.
3.  Since times cannot assume negative values, compute the same quantities of problems (1) and (2) using a normal distribution truncated at zero.



